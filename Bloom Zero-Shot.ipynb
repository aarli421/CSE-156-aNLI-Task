{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "678a574f-3c40-40f2-9bcc-a457e0a9b57b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "008d4e4ea4db4eb0911d13093a26557b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/222 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fdc1a0b8ce949948ee3bbc9f57f5c0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/14.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89740788bada4103b6fc704fe5fa17a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/85.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a56a75adca6a4362b7051738eeb3ac9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/693 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc08bb5163f24d5daee2cdc75e96a04e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.12G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BloomForSequenceClassification were not initialized from the model checkpoint at bigscience/bloom-560m and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BloomForSequenceClassification(\n",
       "  (transformer): BloomModel(\n",
       "    (word_embeddings): Embedding(250880, 1024)\n",
       "    (word_embeddings_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    (h): ModuleList(\n",
       "      (0-23): 24 x BloomBlock(\n",
       "        (input_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (self_attention): BloomAttention(\n",
       "          (query_key_value): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (attention_dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (post_attention_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): BloomMLP(\n",
       "          (dense_h_to_4h): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (gelu_impl): BloomGelu()\n",
       "          (dense_4h_to_h): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (score): Linear(in_features=1024, out_features=3, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "model_name = \"bigscience/bloom-560m\"  \n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=3) \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4173b8b8-7593-4c7c-9ddd-a9852f0e0aec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                  | 0/1532 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "100%|███████████████████████████████████████| 1532/1532 [03:00<00:00,  8.48it/s]\n"
     ]
    }
   ],
   "source": [
    "# Paths to your dataset files\n",
    "dev_jsonl = \"alphanli-train-dev/dev.jsonl\"\n",
    "dev_labels = \"alphanli-train-dev/dev-labels.lst\"\n",
    "\n",
    "def load_data(jsonl_file, labels_file):\n",
    "    data = []\n",
    "    with open(jsonl_file, \"r\") as f_json, open(labels_file, \"r\") as f_labels:\n",
    "        labels = [int(line.strip()) for line in f_labels.readlines()]\n",
    "        for idx, line in enumerate(f_json):\n",
    "            entry = json.loads(line.strip())\n",
    "            data.append({\n",
    "                \"obs1\": entry[\"obs1\"],\n",
    "                \"obs2\": entry[\"obs2\"],\n",
    "                \"hyp1\": entry[\"hyp1\"],\n",
    "                \"hyp2\": entry[\"hyp2\"],\n",
    "                \"label\": labels[idx] \n",
    "            })\n",
    "    return data\n",
    "\n",
    "dev_data = load_data(dev_jsonl, dev_labels)\n",
    "\n",
    "def format_input(entry, hypothesis):\n",
    "    return f\"{entry['obs1']} {entry['obs2']}\", hypothesis\n",
    "\n",
    "def run_inference(model, tokenizer, dataset):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    ground_truths = []\n",
    "\n",
    "    for entry in tqdm(dataset):\n",
    "        inputs = []\n",
    "        labels = []\n",
    "\n",
    "        for i, hyp in enumerate([entry['hyp1'], entry['hyp2']]):\n",
    "            premise, hypothesis = format_input(entry, hyp)\n",
    "            inputs.append((premise, hypothesis))\n",
    "            labels.append(i + 1)  \n",
    "\n",
    "        encodings = tokenizer(\n",
    "            [inp[0] for inp in inputs],  \n",
    "            [inp[1] for inp in inputs], \n",
    "            padding=True, truncation=True, return_tensors=\"pt\"\n",
    "        ).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**encodings)\n",
    "            logits = outputs.logits \n",
    "\n",
    "        \n",
    "        entailment_scores = logits[:, 0] \n",
    "        pred = torch.argmax(entailment_scores).item() + 1  \n",
    "\n",
    "        predictions.append(pred)\n",
    "        ground_truths.append(entry[\"label\"])\n",
    "\n",
    "    return predictions, ground_truths\n",
    "\n",
    "preds, labels = run_inference(model, tokenizer, dev_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e60c1c3a-c6ee-4d6f-8cef-db0ee9aa147a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5072\n",
      "Precision: 0.5170\n",
      "Recall: 0.5070\n",
      "F1-score: 0.5120\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(labels, preds)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average=\"binary\", pos_label=1)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd2ac1c-7822-4aae-8220-74c66bda9764",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
